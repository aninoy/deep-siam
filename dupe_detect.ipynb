{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LWD54k7u2gpN"
   },
   "source": [
    "## Data load and cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim (from -r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/dd/112bd4258cee11e0baaaba064060eb156475a42362e59e3ff28e7ca2d29d/gensim-3.8.1-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.2MB 2.0MB/s eta 0:00:01    49% |████████████████                | 12.1MB 69.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensor2tensor (from -r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/eb/7159c5a12880c496893a5bf7242c23fdb4eed47ade683d111f2f2d4009b4/tensor2tensor-1.14.1-py2.py3-none-any.whl (1.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.6MB 25.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from gensim->-r requirements.txt (line 1)) (1.3.1)\n",
      "Collecting smart-open>=1.8.1 (from gensim->-r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/09/735f2786dfac9bbf39d244ce75c0313d27d4962e71e0774750dc809f2395/smart_open-1.9.0.tar.gz (70kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 31.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from gensim->-r requirements.txt (line 1)) (1.16.4)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from gensim->-r requirements.txt (line 1)) (1.11.0)\n",
      "Collecting gunicorn (from tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/0d/3dbda0324f5bf007f3274e5ea09f0f3bcbf0ca01a75b80ff4f1ff9f8ecfd/gunicorn-20.0.0-py2.py3-none-any.whl (77kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 31.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tqdm (from tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/08/8505f192efc72bfafec79655e1d8351d219e2b80b0dec4ae71f50934c17a/tqdm-4.38.0-py2.py3-none-any.whl (53kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 30.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensor2tensor->-r requirements.txt (line 2)) (2.8.0)\n",
      "Collecting oauth2client (from tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/a9/4f25a14d23f0786b64875b91784607c2277eff25d48f915e39ff0cff505a/oauth2client-4.1.3-py2.py3-none-any.whl (98kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 35.9MB/s a 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-probability==0.7.0 (from tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/3a/c10b6c22320531c774402ac7186d1b673374e2a9d12502cbc8d811e4601c/tensorflow_probability-0.7.0-py2.py3-none-any.whl (981kB)\n",
      "\u001b[K    100% |████████████████████████████████| 983kB 26.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: flask in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensor2tensor->-r requirements.txt (line 2)) (1.0.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensor2tensor->-r requirements.txt (line 2)) (2.20.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensor2tensor->-r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: gevent in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensor2tensor->-r requirements.txt (line 2)) (1.3.0)\n",
      "Collecting opencv-python (from tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/7e/bd5425f4dacb73367fddc71388a47c1ea570839197c2bcad86478e565186/opencv_python-4.1.1.26-cp36-cp36m-manylinux1_x86_64.whl (28.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 28.7MB 1.7MB/s eta 0:00:01    95% |██████████████████████████████▌ | 27.3MB 67.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gin-config (from tensor2tensor->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/98/14/9c671580d1d344be5f66d81a898aacb028beb2d8a271a731894eada0f839/gin-config-0.2.1.tar.gz\n",
      "Collecting google-api-python-client (from tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/19/9fd511734c0dee8fa3d49f4109c75e7f95d3c31ed76c0e4a93fbba147807/google-api-python-client-1.7.11.tar.gz (142kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 36.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting bz2file (from tensor2tensor->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
      "Collecting mesh-tensorflow (from tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/10/7bbf9f19bbd57693b7cd66358ad432ea358e2af24d0f444ec6abf6385f49/mesh_tensorflow-0.1.4-py2.py3-none-any.whl (224kB)\n",
      "\u001b[K    100% |████████████████████████████████| 225kB 37.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pypng (from tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/fb/f719f1ac965e2101aa6ea6f54ef8b40f8fbb033f6ad07c017663467f5147/pypng-0.0.20.tar.gz (649kB)\n",
      "\u001b[K    100% |████████████████████████████████| 655kB 30.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensor2tensor->-r requirements.txt (line 2)) (5.2.0)\n",
      "Collecting tensorflow-gan (from tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/2e/62922111d7d50e1900e3030764743ea7735540ce103b3ab30fd5cd2d8a2b/tensorflow_gan-2.0.0-py2.py3-none-any.whl (365kB)\n",
      "\u001b[K    100% |████████████████████████████████| 368kB 33.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting kfac (from tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/f0/4a7758f854a15b37d322827123ce58619d0f4270dd94f2dd30328f397339/kfac-0.2.0-py2.py3-none-any.whl (178kB)\n",
      "\u001b[K    100% |████████████████████████████████| 184kB 40.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-datasets (from tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/14/900746f9b8e1ed8ea93661f1a62b3937a5a25858d550ece38de8ea579f2d/tensorflow_datasets-1.3.0-py3-none-any.whl (2.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.4MB 4.0MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting dopamine-rl (from tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/1c/99be0c9325dad3ce11ec6088408ebdb5bc7194791fd40df8b6be28a23973/dopamine_rl-2.0.5.tar.gz (54kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 30.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting gym (from tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/85/a7a462d7796f097027d60f9a62b4e17a0a94dcf12ac2a9f9a913333b11a6/gym-0.15.4.tar.gz (1.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.6MB 15.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting future (from tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
      "\u001b[K    100% |████████████████████████████████| 829kB 27.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: boto>=2.32 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim->-r requirements.txt (line 1)) (2.48.0)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim->-r requirements.txt (line 1)) (1.10.18)\n",
      "Requirement already satisfied: setuptools>=3.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from gunicorn->tensor2tensor->-r requirements.txt (line 2)) (41.5.1)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from oauth2client->tensor2tensor->-r requirements.txt (line 2)) (3.4.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyasn1-modules>=0.0.5 (from oauth2client->tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/50/bb4cefca37da63a0c52218ba2cb1b1c36110d84dcbae8aa48cd67c5e95c2/pyasn1_modules-0.2.7-py2.py3-none-any.whl (131kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 35.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting httplib2>=0.9.1 (from oauth2client->tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/84/f97b9efdb17c9b73e133bdbf2b4bfd09cd0be655e36e3ee3c4bec9095048/httplib2-0.14.0-py3-none-any.whl (94kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 36.3MB/s a 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.7 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from oauth2client->tensor2tensor->-r requirements.txt (line 2)) (0.4.7)\n",
      "Collecting cloudpickle>=0.6.1 (from tensorflow-probability==0.7.0->tensor2tensor->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/c1/49/334e279caa3231255725c8e860fa93e72083567625573421db8875846c14/cloudpickle-1.2.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-probability==0.7.0->tensor2tensor->-r requirements.txt (line 2)) (4.3.0)\n",
      "Requirement already satisfied: Werkzeug>=0.14 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from flask->tensor2tensor->-r requirements.txt (line 2)) (0.14.1)\n",
      "Requirement already satisfied: Jinja2>=2.10 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from flask->tensor2tensor->-r requirements.txt (line 2)) (2.10)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from flask->tensor2tensor->-r requirements.txt (line 2)) (0.24)\n",
      "Requirement already satisfied: click>=5.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from flask->tensor2tensor->-r requirements.txt (line 2)) (6.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->tensor2tensor->-r requirements.txt (line 2)) (3.0.4)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->tensor2tensor->-r requirements.txt (line 2)) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->tensor2tensor->-r requirements.txt (line 2)) (2019.9.11)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->tensor2tensor->-r requirements.txt (line 2)) (1.23)\n",
      "Requirement already satisfied: greenlet>=0.4.13 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from gevent->tensor2tensor->-r requirements.txt (line 2)) (0.4.13)\n",
      "Collecting google-auth>=1.4.1 (from google-api-python-client->tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/cb/786dc53d93494784935a62947643b48250b84a882474e714f9af5e1a1928/google_auth-1.7.1-py2.py3-none-any.whl (74kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 15.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-httplib2>=0.0.3 (from google-api-python-client->tensor2tensor->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/33/49/c814d6d438b823441552198f096fcd0377fd6c88714dbed34f1d3c8c4389/google_auth_httplib2-0.0.3-py2.py3-none-any.whl\n",
      "Collecting uritemplate<4dev,>=3.0.0 (from google-api-python-client->tensor2tensor->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/e5/7d/9d5a640c4f8bf2c8b1afc015e9a9d8de32e13c9016dcc4b0ec03481fb396/uritemplate-3.0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: absl-py in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from mesh-tensorflow->tensor2tensor->-r requirements.txt (line 2)) (0.8.1)\n",
      "Collecting tensorflow-hub>=0.2 (from tensorflow-gan->tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/0e/a91780d07592b1abf9c91344ce459472cc19db3b67fdf3a61dca6ebb2f5c/tensorflow_hub-0.7.0-py2.py3-none-any.whl (89kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 34.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting dill (from tensorflow-datasets->tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 40.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-datasets->tensor2tensor->-r requirements.txt (line 2)) (1.11.2)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-datasets->tensor2tensor->-r requirements.txt (line 2)) (18.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-datasets->tensor2tensor->-r requirements.txt (line 2)) (3.7.1)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-datasets->tensor2tensor->-r requirements.txt (line 2)) (1.1.0)\n",
      "Collecting promise (from tensorflow-datasets->tensor2tensor->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/5a/81/221d09d90176fd90aed4b530e31b8fedf207385767c06d1d46c550c5e418/promise-2.2.1.tar.gz\n",
      "Collecting tensorflow-metadata (from tensorflow-datasets->tensor2tensor->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/00/f353385e40f7962b63b94d17f7050b5853bc20c243483cff0cb3da03d206/tensorflow_metadata-0.15.1-py2.py3-none-any.whl\n",
      "Collecting pyglet<=1.3.2,>=1.2.0 (from gym->tensor2tensor->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.0MB 26.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: botocore<1.14.0,>=1.13.18 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim->-r requirements.txt (line 1)) (1.13.18)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim->-r requirements.txt (line 1)) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim->-r requirements.txt (line 1)) (0.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from Jinja2>=2.10->flask->tensor2tensor->-r requirements.txt (line 2)) (1.0)\n",
      "Collecting cachetools<3.2,>=2.0.0 (from google-auth>=1.4.1->google-api-python-client->tensor2tensor->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Collecting googleapis-common-protos (from tensorflow-metadata->tensorflow-datasets->tensor2tensor->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/ee/e59e74ecac678a14d6abefb9054f0bbcb318a6452a30df3776f133886d7d/googleapis-common-protos-1.6.0.tar.gz\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.18->boto3->smart-open>=1.8.1->gensim->-r requirements.txt (line 1)) (2.7.3)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.18->boto3->smart-open>=1.8.1->gensim->-r requirements.txt (line 1)) (0.14)\n",
      "Building wheels for collected packages: smart-open, gin-config, google-api-python-client, bz2file, pypng, dopamine-rl, gym, future, dill, promise, googleapis-common-protos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running setup.py bdist_wheel for smart-open ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/ab/10/93/5cff86f5b721d77edaecc29959b1c60d894be1f66d91407d28\n",
      "  Running setup.py bdist_wheel for gin-config ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/ce/c8/46/5e7bf52dc31cb4fe1b541c27463b970150b2d8651105784a32\n",
      "  Running setup.py bdist_wheel for google-api-python-client ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/b8/f6/f5/b7bef1a5bc0e07ca4aa54c596b0b574c5afc07a9fddccf08f8\n",
      "  Running setup.py bdist_wheel for bz2file ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
      "  Running setup.py bdist_wheel for pypng ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/41/6b/ef/0493b536b6d4722c2ae9486691b1d49b922b9877922beeabb3\n",
      "  Running setup.py bdist_wheel for dopamine-rl ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/75/01/fa/43ebcfe0f37d8c27bb1b7b6fa213caa0340e783fe754a2af8f\n",
      "  Running setup.py bdist_wheel for gym ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/e9/26/9b/8a1a6599a91077a938ac4348cc3d3ac84bfab0dbfddeb4c6e7\n",
      "  Running setup.py bdist_wheel for future ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
      "  Running setup.py bdist_wheel for dill ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
      "  Running setup.py bdist_wheel for promise ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/92/84/9f/75e2235effae0e1c5a5c0626a503e532bbffcb7e79e672b606\n",
      "  Running setup.py bdist_wheel for googleapis-common-protos ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/9e/3d/a2/1bec8bb7db80ab3216dbc33092bb7ccd0debfb8ba42b5668d5\n",
      "Successfully built smart-open gin-config google-api-python-client bz2file pypng dopamine-rl gym future dill promise googleapis-common-protos\n",
      "Installing collected packages: smart-open, gensim, gunicorn, tqdm, pyasn1-modules, httplib2, oauth2client, cloudpickle, tensorflow-probability, opencv-python, gin-config, cachetools, google-auth, google-auth-httplib2, uritemplate, google-api-python-client, bz2file, future, mesh-tensorflow, pypng, tensorflow-hub, tensorflow-gan, kfac, dill, promise, googleapis-common-protos, tensorflow-metadata, tensorflow-datasets, pyglet, gym, dopamine-rl, tensor2tensor\n",
      "  Found existing installation: cloudpickle 0.5.3\n",
      "    Uninstalling cloudpickle-0.5.3:\n",
      "      Successfully uninstalled cloudpickle-0.5.3\n",
      "Successfully installed bz2file-0.98 cachetools-3.1.1 cloudpickle-1.2.2 dill-0.3.1.1 dopamine-rl-2.0.5 future-0.18.2 gensim-3.8.1 gin-config-0.2.1 google-api-python-client-1.7.11 google-auth-1.7.1 google-auth-httplib2-0.0.3 googleapis-common-protos-1.6.0 gunicorn-20.0.0 gym-0.15.4 httplib2-0.14.0 kfac-0.2.0 mesh-tensorflow-0.1.4 oauth2client-4.1.3 opencv-python-4.1.1.26 promise-2.2.1 pyasn1-modules-0.2.7 pyglet-1.3.2 pypng-0.0.20 smart-open-1.9.0 tensor2tensor-1.14.1 tensorflow-datasets-1.3.0 tensorflow-gan-2.0.0 tensorflow-hub-0.7.0 tensorflow-metadata-0.15.1 tensorflow-probability-0.7.0 tqdm-4.38.0 uritemplate-3.0.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "rFo8iurB3zQK",
    "outputId": "21904f1e-c25b-4aa2-e5a5-3b36fe49bc4f"
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "89jYW8HHeA-B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already downloaded.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "from utils import get_raw_data, data_download\n",
    "\n",
    "data_path = get_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i6SZz6nLb2eD"
   },
   "outputs": [],
   "source": [
    "entity_type = \"movie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "7UkY-36GKy8p",
    "outputId": "73157ff8-06c6-42d7-8db9-2da4358a4ec9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>name</th>\n",
       "      <th>premiere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fox is an edge-of-the-seat suspense thriller t...</td>\n",
       "      <td>fb12ea15f0a94392998e6ba8f0828593</td>\n",
       "      <td>Drama,International,Mystery</td>\n",
       "      <td>Fox</td>\n",
       "      <td>2009-09-04T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In Washington, D.C., in the year 2054, murder ...</td>\n",
       "      <td>ed090fa63254441ab3d4dd83c9ddc891</td>\n",
       "      <td>Action,Adventure,Science Fiction</td>\n",
       "      <td>Minority Report</td>\n",
       "      <td>2002-06-21T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andrew McMahon has a momentous year: He releas...</td>\n",
       "      <td>b2725ec69dc54f5e9a687c84487cf30a</td>\n",
       "      <td>Documentaries</td>\n",
       "      <td>Dear Jack</td>\n",
       "      <td>2009-01-01T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>From The Producer of THE STRANGERS and the wri...</td>\n",
       "      <td>93c2491ae356408d8d04a63907b42fee</td>\n",
       "      <td>Horror,Supernatural</td>\n",
       "      <td>At The Devil's Door</td>\n",
       "      <td>2014-08-08T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Filmmaker Tommy Davis follows four Mexican mig...</td>\n",
       "      <td>fecd9360da1d4370b91481eec4621d18</td>\n",
       "      <td>Documentaries</td>\n",
       "      <td>Mojados: Through the Night</td>\n",
       "      <td>2004-03-12T00:00:00.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          description  \\\n",
       "0   Fox is an edge-of-the-seat suspense thriller t...   \n",
       "3   In Washington, D.C., in the year 2054, murder ...   \n",
       "4   Andrew McMahon has a momentous year: He releas...   \n",
       "6   From The Producer of THE STRANGERS and the wri...   \n",
       "10  Filmmaker Tommy Davis follows four Mexican mig...   \n",
       "\n",
       "                           entity_id                            genres  \\\n",
       "0   fb12ea15f0a94392998e6ba8f0828593       Drama,International,Mystery   \n",
       "3   ed090fa63254441ab3d4dd83c9ddc891  Action,Adventure,Science Fiction   \n",
       "4   b2725ec69dc54f5e9a687c84487cf30a                     Documentaries   \n",
       "6   93c2491ae356408d8d04a63907b42fee               Horror,Supernatural   \n",
       "10  fecd9360da1d4370b91481eec4621d18                     Documentaries   \n",
       "\n",
       "                          name                  premiere  \n",
       "0                          Fox  2009-09-04T00:00:00.000Z  \n",
       "3              Minority Report  2002-06-21T00:00:00.000Z  \n",
       "4                    Dear Jack  2009-01-01T00:00:00.000Z  \n",
       "6          At The Devil's Door  2014-08-08T00:00:00.000Z  \n",
       "10  Mojados: Through the Night  2004-03-12T00:00:00.000Z  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_training_dataset(entity_type):\n",
    "  with open(os.path.join(data_path, 'train.json'), 'r') as f:\n",
    "    train_df = pd.read_json(f)\n",
    "    \n",
    "    train_df = train_df[train_df.entity_type==entity_type]\n",
    "    train_df.drop(columns=['entity_type', 'episode_number', 'problem_space', 'season_number', 'series_description', 'series_entity_id', 'series_name', 'series_premiere'], inplace=True)\n",
    "    train_df.drop(columns=['ver_id', 'id', 'source_id'], inplace=True)\n",
    "  \n",
    "  return train_df\n",
    "\n",
    "\n",
    "train_df = load_training_dataset(entity_type)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kl11xO1E2osu"
   },
   "source": [
    "## genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "OJcMl4alDTkT",
    "outputId": "d32bc3a4-5327-4b72-d130-ec35bc8a1794"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [1, 2, 3]\n",
       "3     [4, 5, 6]\n",
       "4           [7]\n",
       "6        [8, 9]\n",
       "10          [7]\n",
       "Name: genres, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_dict = {'next': 1}\n",
    "\n",
    "\n",
    "def genre_array_to_dict(row):\n",
    "  genre_mapping = []\n",
    "  for g in row:\n",
    "    next_genre = genre_dict['next']\n",
    "    g_num = genre_dict.setdefault(g, next_genre)\n",
    "    if g_num == next_genre:\n",
    "      genre_dict['next'] += 1\n",
    "    genre_mapping.append(g_num)\n",
    "  return genre_mapping\n",
    "  \n",
    "genres_df = train_df.genres.str.split(',').apply(lambda x: genre_array_to_dict(x))\n",
    "genres_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZCTEz312vsW"
   },
   "source": [
    "## descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "ggLyvcYILBL4",
    "outputId": "718a7949-25cd-41d4-d9f0-552814a81cc8",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     fox edge seat suspense thriller moves high spe...\n",
       "3            washington d c year 2054 murder eliminated\n",
       "4     andrew mcmahon momentous year releases album b...\n",
       "6     producer strangers writer director pact comes ...\n",
       "10    filmmaker tommy davis follows mexican migrants...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string, strip_multiple_whitespaces, strip_non_alphanum, strip_punctuation, remove_stopwords\n",
    "CUSTOM_FILTERS = [lambda x: x.lower(), strip_multiple_whitespaces, strip_non_alphanum, strip_punctuation, remove_stopwords]\n",
    "\n",
    "def preprocess(row):\n",
    "  if not row:\n",
    "    return ''\n",
    "  return ' '.join(preprocess_string(row, CUSTOM_FILTERS))\n",
    "\n",
    "description_string_df = train_df.description.apply(lambda x: preprocess(x))\n",
    "description_string_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "qLWOJHC0PFGU",
    "outputId": "e2f1b07c-b43a-46e5-f40c-5c359e7c6d17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [104, 113, 122, 34, 103, 102, 105, 103, 34, 11...\n",
       "3     [121, 99, 117, 106, 107, 112, 105, 118, 113, 1...\n",
       "4     [99, 112, 102, 116, 103, 121, 34, 111, 101, 11...\n",
       "6     [114, 116, 113, 102, 119, 101, 103, 116, 34, 1...\n",
       "10    [104, 107, 110, 111, 111, 99, 109, 103, 116, 3...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensor2tensor.data_generators import text_encoder\n",
    "\n",
    "description_df = description_string_df.apply(lambda x: text_encoder.ByteTextEncoder().encode(x))\n",
    "description_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7jC2q5xz26Rc"
   },
   "source": [
    "## titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "NBQ4n0e-2aor",
    "outputId": "53f8f41c-a65a-4e5d-d916-11fe07182729"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        [72, 113, 122]\n",
       "3     [79, 107, 112, 113, 116, 107, 118, 123, 34, 84...\n",
       "4              [70, 103, 99, 116, 34, 76, 99, 101, 109]\n",
       "6     [67, 118, 34, 86, 106, 103, 34, 70, 103, 120, ...\n",
       "10    [79, 113, 108, 99, 102, 113, 117, 60, 34, 86, ...\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_df = train_df.name.apply(lambda x: text_encoder.ByteTextEncoder().encode(x))\n",
    "name_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jtnrdnLL29QX"
   },
   "source": [
    "## dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "7S3i1hRY3Cri",
    "outputId": "26ed84c3-7609-4d3d-db8b-d496b0257e37"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2004</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  month  day\n",
       "0   2009      9    4\n",
       "3   2002      6   21\n",
       "4   2009      1    1\n",
       "6   2014      8    8\n",
       "10  2004      3   12"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.to_datetime(train_df.premiere)\n",
    "year_df = dates.dt.year.rename('year')\n",
    "month_df = dates.dt.month.rename('month')\n",
    "day_df = dates.dt.day.rename('day')\n",
    "dates_df = pd.concat([year_df, month_df, day_df], axis=1)\n",
    "dates_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nPboHuEUCBTn"
   },
   "source": [
    "## preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "yCA20RepKrUa",
    "outputId": "396379d6-0c0c-4f2a-a3ae-e279bc2ddbab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>genres</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fb12ea15f0a94392998e6ba8f0828593</td>\n",
       "      <td>[72, 113, 122]</td>\n",
       "      <td>[104, 113, 122, 34, 103, 102, 105, 103, 34, 11...</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ed090fa63254441ab3d4dd83c9ddc891</td>\n",
       "      <td>[79, 107, 112, 113, 116, 107, 118, 123, 34, 84...</td>\n",
       "      <td>[121, 99, 117, 106, 107, 112, 105, 118, 113, 1...</td>\n",
       "      <td>[4, 5, 6]</td>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b2725ec69dc54f5e9a687c84487cf30a</td>\n",
       "      <td>[70, 103, 99, 116, 34, 76, 99, 101, 109]</td>\n",
       "      <td>[99, 112, 102, 116, 103, 121, 34, 111, 101, 11...</td>\n",
       "      <td>[7]</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93c2491ae356408d8d04a63907b42fee</td>\n",
       "      <td>[67, 118, 34, 86, 106, 103, 34, 70, 103, 120, ...</td>\n",
       "      <td>[114, 116, 113, 102, 119, 101, 103, 116, 34, 1...</td>\n",
       "      <td>[8, 9]</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fecd9360da1d4370b91481eec4621d18</td>\n",
       "      <td>[79, 113, 108, 99, 102, 113, 117, 60, 34, 86, ...</td>\n",
       "      <td>[104, 107, 110, 111, 111, 99, 109, 103, 116, 3...</td>\n",
       "      <td>[7]</td>\n",
       "      <td>2004</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          entity_id  \\\n",
       "0  fb12ea15f0a94392998e6ba8f0828593   \n",
       "1  ed090fa63254441ab3d4dd83c9ddc891   \n",
       "2  b2725ec69dc54f5e9a687c84487cf30a   \n",
       "3  93c2491ae356408d8d04a63907b42fee   \n",
       "4  fecd9360da1d4370b91481eec4621d18   \n",
       "\n",
       "                                                name  \\\n",
       "0                                     [72, 113, 122]   \n",
       "1  [79, 107, 112, 113, 116, 107, 118, 123, 34, 84...   \n",
       "2           [70, 103, 99, 116, 34, 76, 99, 101, 109]   \n",
       "3  [67, 118, 34, 86, 106, 103, 34, 70, 103, 120, ...   \n",
       "4  [79, 113, 108, 99, 102, 113, 117, 60, 34, 86, ...   \n",
       "\n",
       "                                         description     genres  year  month  \\\n",
       "0  [104, 113, 122, 34, 103, 102, 105, 103, 34, 11...  [1, 2, 3]  2009      9   \n",
       "1  [121, 99, 117, 106, 107, 112, 105, 118, 113, 1...  [4, 5, 6]  2002      6   \n",
       "2  [99, 112, 102, 116, 103, 121, 34, 111, 101, 11...        [7]  2009      1   \n",
       "3  [114, 116, 113, 102, 119, 101, 103, 116, 34, 1...     [8, 9]  2014      8   \n",
       "4  [104, 107, 110, 111, 111, 99, 109, 103, 116, 3...        [7]  2004      3   \n",
       "\n",
       "   day  \n",
       "0    4  \n",
       "1   21  \n",
       "2    1  \n",
       "3    8  \n",
       "4   12  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.concat([train_df.entity_id, name_df, description_df, genres_df, year_df, month_df, day_df], axis=1).reset_index(drop=True)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "0UNgRGEYVgKB",
    "outputId": "eeeacaae-2522-4d14-c8f4-b22b32bdb1ab"
   },
   "outputs": [],
   "source": [
    "width = max(data_df.description.str.len())\n",
    "\n",
    "feature_vector = []\n",
    "\n",
    "for i,row in data_df.iterrows():\n",
    "  v = np.vstack([np.pad(row['name'], (0, width-len(row['name'])), 'constant', constant_values=0), \n",
    "                 np.pad(row.description, (0, width-len(row.description)), 'constant', constant_values=0), \n",
    "                 np.pad(row.genres, (0, width-len(row.genres)), 'constant', constant_values=0), \n",
    "                 np.pad([row.year, row.month, row.day], (0, width-3), 'constant', constant_values=0)])\n",
    "  feature_vector.append(v)\n",
    "  if len(feature_vector) > 1000: \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "arzW5gPIVknZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "print(len(feature_vector))\n",
    "dataset = np.array(feature_vector)\n",
    "dataset.shape\n",
    "np.save(os.path.join(data_path, 'dataset.npy'), dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0CrOaLOTr311"
   },
   "outputs": [],
   "source": [
    "del feature_vector\n",
    "del train_df, name_df, genres_df, description_df, description_string_df, year_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5h7QU2IKSH9"
   },
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tPRzxT9HJvD1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already downloaded.\n"
     ]
    }
   ],
   "source": [
    "data_download(filename=\"dataset.npy\")\n",
    "dataset = np.load(os.path.join(data_path, 'dataset.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xz6hlQOOC_0b"
   },
   "source": [
    "## generate positive & negative samples\n",
    "label : index, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8pKNnKNbmNy"
   },
   "outputs": [],
   "source": [
    "pos_neg_ratio = 50 \n",
    "use_single_groups = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QnDJ8q8tMQPS"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-416099e2861a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'id_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'id_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mraw_samples_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'entity_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madd_group_to_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def add_group_to_samples(g):\n",
    "  matches = []\n",
    "  g_array = g.index.data\n",
    "  for pair in combinations(g_array, 2):\n",
    "    matches.append([1, pair[0], pair[1]])\n",
    "  if matches:\n",
    "    return pd.DataFrame(matches, columns=['label', 'id_1', 'id_2'])\n",
    "  else:\n",
    "    return pd.DataFrame([[0, g_array[0], -1]], columns=['label', 'id_1', 'id_2'])\n",
    "  \n",
    "raw_samples_df = data_df.groupby(by='entity_id').apply(lambda x: add_group_to_samples(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPvG4YSoR0S3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>level_1</th>\n",
       "      <th>label</th>\n",
       "      <th>id_1</th>\n",
       "      <th>id_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000325d35532430585fcf5756d590f1e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13757</td>\n",
       "      <td>21659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003e0b99f1e4d808985516e652f8609</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7403</td>\n",
       "      <td>19052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003e0b99f1e4d808985516e652f8609</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7403</td>\n",
       "      <td>20103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003e0b99f1e4d808985516e652f8609</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19052</td>\n",
       "      <td>20103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00045f7e206440beb55b82518517f7b4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>8126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          entity_id  level_1  label   id_1   id_2\n",
       "0  000325d35532430585fcf5756d590f1e        0      1  13757  21659\n",
       "1  0003e0b99f1e4d808985516e652f8609        0      1   7403  19052\n",
       "2  0003e0b99f1e4d808985516e652f8609        1      1   7403  20103\n",
       "3  0003e0b99f1e4d808985516e652f8609        2      1  19052  20103\n",
       "4  00045f7e206440beb55b82518517f7b4        0      1    128   8126"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_samples_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kj4BibO5S78u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total positive samples:  21717\n",
      "total representations with no pair:  944\n",
      "total groups for negative samples to match against:  8227\n"
     ]
    }
   ],
   "source": [
    "pos = raw_samples_df[raw_samples_df.label == 1].shape[0]\n",
    "no_pair = raw_samples_df[raw_samples_df.label == 0].shape[0]\n",
    "unique_match_groups = len(raw_samples_df[raw_samples_df.label == 1].groupby(by='entity_id'))\n",
    "print('total positive samples: ', pos)\n",
    "print('total representations with no pair: ', no_pair)\n",
    "print('total groups for negative samples to match against: ', unique_match_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cccECvJDf9b7"
   },
   "outputs": [],
   "source": [
    "raw_samples = raw_samples_df[['label', 'id_1', 'id_2']].to_numpy()\n",
    "del raw_samples_df\n",
    "\n",
    "pos_pairs = raw_samples[raw_samples[:,0] == 1]\n",
    "negs = np.tile(raw_samples[raw_samples[:,0] == 0][:, 1], 50)\n",
    "neg_pos = np.random.choice(raw_samples[raw_samples[:,0] == 1,1:].flatten(), size=(negs.shape[0]))\n",
    "neg_pairs = np.vstack([np.zeros_like(negs), negs, neg_pos]).T\n",
    "\n",
    "del raw_samples\n",
    "# data_pairs = np.vstack((raw_samples[raw_samples[:,0] == 1], np.vstack([np.zeros_like(negs), negs, neg_pairs]).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4fi9Bc2Cx9EJ"
   },
   "outputs": [],
   "source": [
    "del data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tw-uHWwjutAx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cGw_b6XBpdmh"
   },
   "outputs": [],
   "source": [
    "pos_train, pos_not_train = train_test_split(pos_pairs, test_size=.3)\n",
    "neg_train, neg_not_train = train_test_split(neg_pairs, test_size=.3)\n",
    "\n",
    "\n",
    "pos_test, pos_dev = train_test_split(pos_not_train, test_size=.5)\n",
    "neg_test, neg_dev = train_test_split(neg_not_train, test_size=.5)\n",
    "\n",
    "del pos_not_train, neg_not_train\n",
    "\n",
    "\n",
    "np.save(os.path.join(data_path, 'train'), np.vstack((pos_train, neg_train)))\n",
    "np.save(os.path.join(data_path, 'test'), np.vstack((pos_test, neg_test)))\n",
    "np.save(os.path.join(data_path, 'dev'), np.vstack((pos_dev, neg_dev)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DPt-UtVJn4_K"
   },
   "source": [
    "# Siamese Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWTtoiziomXE"
   },
   "source": [
    "### Initialize with imports for keras and tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Utq7WNuvnaas",
    "outputId": "0f466b11-439d-48ac-ac2a-9ff6d546a590"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, Activation, Input, concatenate\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.core import Dense, Flatten, Lambda\n",
    "from keras.regularizers import l2\n",
    "from keras.engine.topology import Layer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "\n",
    "# np.set_printoptions(threshold=np.nan)\n",
    "model_path = os.path.join(data_path, \"model.v4.h5\")\n",
    "model_weights_path = os.path.join(data_path, \"model_weights_95.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3x9C0yHsrVJY"
   },
   "source": [
    "### Initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "F7xjAyjUrZVY",
    "outputId": "12e166b5-eee3-4c28-be20-8521bdbee415"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6521: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  alternative=\"'density'\", removal=\"3.1\")\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6521: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  alternative=\"'density'\", removal=\"3.1\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def initialize_weights(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)\n",
    "  \n",
    "\n",
    "def initialize_bias(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)\n",
    "  \n",
    "weights = initialize_weights((1000,1))\n",
    "sns.distplot(weights)\n",
    "# plt.title(\"Plot of weights initialized, with mean of 0.0 and standard deviation of 0.01\")\n",
    "bias = initialize_bias((1000,1))\n",
    "sns.distplot(bias)\n",
    "# plt.title(\"Plot of biases initialized, with mean of 0.0 and standard deviation of 0.01\")\n",
    "\n",
    "class CustomWeightsInitializer:\n",
    "  def __call__(self, shape):\n",
    "    return initialize_weights(shape)\n",
    "  \n",
    "class CustomBiasInitializer:\n",
    "  def __call__(self, shape):\n",
    "    return initialize_bias(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R3yJwVZyqDwd"
   },
   "source": [
    "\n",
    "\n",
    "### Define the network architecture for siam net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ooLmZpqVPr09"
   },
   "outputs": [],
   "source": [
    "def get_encoder_model(input_shape):\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(4, (1,48), activation='relu', input_shape=input_shape, \n",
    "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-3)))\n",
    "  model.add(MaxPooling2D(pool_size=(1,16), strides=(1,8)))\n",
    "  model.add(Conv2D(16, (1,24), activation='tanh', input_shape=input_shape, \n",
    "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-3)))\n",
    "  model.add(MaxPooling2D(pool_size=(1,8), strides=(1,4)))\n",
    "  model.add(Conv2D(32, (1,12), activation='tanh', input_shape=input_shape, \n",
    "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-3)))\n",
    "  model.add(MaxPooling2D(pool_size=(1,4), strides=(1,2)))\n",
    "  model.add(Conv2D(64, (4,1), activation='tanh', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-3)))\n",
    "  model.add(Flatten())\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i3z_t2zkclUb"
   },
   "outputs": [],
   "source": [
    "def get_experimental_encoder_model(input_shape):\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(4, (1,48), activation='relu', input_shape=input_shape, \n",
    "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-3)))\n",
    "  model.add(MaxPooling2D(pool_size=(1,16), strides=(1,8)))\n",
    "  model.add(Conv2D(16, (1,24), activation='tanh', input_shape=input_shape, \n",
    "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-3)))\n",
    "  model.add(MaxPooling2D(pool_size=(1,8), strides=(1,4)))\n",
    "  model.add(Conv2D(32, (4,1), activation='tanh', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-3)))\n",
    "  model.add(Flatten())\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ZUQJ3CTq11v"
   },
   "outputs": [],
   "source": [
    "def get_siamese_model(input_shape):\n",
    "    \"\"\"\n",
    "        Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "    \"\"\"\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    encoder_model = get_encoder_model(input_shape)\n",
    "    encoded_l = encoder_model(left_input)\n",
    "    encoded_r = encoder_model(right_input)\n",
    "    \n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(L1_distance)\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    optimizer = Adam(lr=0.00006)\n",
    "    siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QQrA2Jy_rOY1"
   },
   "source": [
    "verify the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "colab_type": "code",
    "id": "Ive9Cfx2rQE5",
    "outputId": "d132bb53-cba9-4061-e5aa-d8c2a3849dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 4, 3800, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 4, 3800, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 3072)         16180       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 3072)         0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            3073        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 19,253\n",
      "Trainable params: 19,253\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_siamese_model((4, 3800, 1))\n",
    "model.summary()\n",
    "model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DN55uXxy4ONA"
   },
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSEKuABSLb7A"
   },
   "outputs": [],
   "source": [
    "data_download(filename='dataset.npy')\n",
    "def load_dataset():\n",
    "  dataset = np.load(os.path.join(data_path, 'dataset.npy'))\n",
    "  return dataset\n",
    "\n",
    "dataset = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tz8E47EOO_Z"
   },
   "outputs": [],
   "source": [
    "dataset[0:3].T.shape\n",
    "input_shape = (dataset.shape[1], dataset.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "KsPiKXCk42Gk",
    "outputId": "838f616d-0a0e-456e-da24-d7cb8c4b0a47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ./data/train.npy\n",
      "loading data from ./data/dev.npy\n",
      "loading data from ./data/test.npy\n"
     ]
    }
   ],
   "source": [
    "class Siamese_Loader:\n",
    "    \"\"\"For loading batches and testing tasks to a siamese net\"\"\"\n",
    "    def __init__(self, path, data_subsets = [\"train\", \"dev\", \"test\"]):\n",
    "        self.data = {}\n",
    "        self.categories = {}\n",
    "        self.info = {}\n",
    "        \n",
    "        for name in data_subsets:\n",
    "            file_path = os.path.join(path, name + \".npy\")\n",
    "            print(\"loading data from {}\".format(file_path))\n",
    "            with open(file_path,\"rb\") as f:\n",
    "                data = np.load(f)\n",
    "                X = data[:, 1:]\n",
    "                y = data[:, 0]\n",
    "                self.data[name] = X\n",
    "                self.categories[name] = y\n",
    "\n",
    "    def get_batch(self,batch_size,s=\"train\"):\n",
    "        \n",
    "        start = 0\n",
    "        while True:\n",
    "            end = min(start+batch_size, self.data[s].shape[0])\n",
    "            p1, p2 = self.data[s][start:end].T\n",
    "            yield [dataset[p1][...,np.newaxis], dataset[p2][...,np.newaxis]], self.categories[s][start:end]\n",
    "            if end == self.data[s].shape[0]:\n",
    "              start = - batch_size\n",
    "            start += batch_size\n",
    "    \n",
    "    def generate(self, batch_size, s=\"train\"):\n",
    "        \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
    "        while True:\n",
    "            pairs, targets = self.get_batch(batch_size,s)\n",
    "            yield (pairs, targets)    \n",
    "    \n",
    "    def train(self, model, epochs, batch_size=32):\n",
    "        train_steps = loader.data['train'].shape[0] // batch_size\n",
    "        validation_steps = loader.data['dev'].shape[0] // batch_size\n",
    "        callbacks = [ModelCheckpoint(model_path, monitor='val_acc', \n",
    "                                                               save_best_only=True)]\n",
    "        history = model.fit_generator(self.get_batch(batch_size), \n",
    "                                      steps_per_epoch=train_steps, epochs=epochs, \n",
    "                                      validation_data=self.get_batch(batch_size, s='dev'),\n",
    "                                      validation_steps=validation_steps,\n",
    "                                      callbacks=callbacks)\n",
    "        return history\n",
    "      \n",
    "    def evaluate(self, model, batch_size=32):\n",
    "        steps = loader.data['test'].shape[0] // batch_size\n",
    "        history = model.evaluate_generator(self.get_batch(batch_size, s='test'), batch_size)\n",
    "        return history\n",
    "        \n",
    "    \n",
    "loader = Siamese_Loader(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The authenticity of host 'github.com (140.82.114.3)' can't be established.\r\n",
      "RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.\r\n",
      "RSA key fingerprint is MD5:16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.\r\n",
      "Are you sure you want to continue connecting (yes/no)? "
     ]
    }
   ],
   "source": [
    "!git remote set-url origin git@github.com:aninoy/deep-siam.git\n",
    "!git remote show origin\n",
    "# !git push origin master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9IPvWYm11MPS"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-JDVbWZ5R2CP"
   },
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "  model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "olXjGgtUlhVN"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  import matplotlib.pyplot as plt\n",
    "\n",
    "  # Plot training & validation accuracy values\n",
    "  plt.plot(history.history['acc'])\n",
    "  plt.plot(history.history['val_acc'])\n",
    "  plt.title('Model accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Test'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  # Plot training & validation loss values\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.plot(history.history['val_loss'])\n",
    "  plt.title('Model loss')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Test'], loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vdIaNNljxQm"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, batch_size):\n",
    "  results = loader.evaluate(model, batch_size=batch_size)\n",
    "  print(\"Test results\")\n",
    "  print(\"--------------\")\n",
    "  print(list(zip(model.metrics_names, results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_541hplP1RSc"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, batch_size=32, epochs=10):\n",
    "  print(\"Starting training process!\")\n",
    "  print(\"-------------------------------------\")\n",
    "  \n",
    "  t_start = time.time()\n",
    "  \n",
    "  history = loader.train(model, epochs, batch_size)\n",
    "  \n",
    "  print(\"Time for training: {0}\".format(time.time()-t_start))\n",
    "  \n",
    "  evaluate(model, batch_size)\n",
    "  \n",
    "  return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GgU2FBL7R8Mn"
   },
   "outputs": [],
   "source": [
    "def load_saved_model(refresh=False):\n",
    "  \n",
    "  # check if entire model is saved\n",
    "  if not refresh and os.path.exists(model_path) and os.path.isfile(model_path):\n",
    "    custom_objects = {\n",
    "      'initialize_weights': CustomWeightsInitializer,\n",
    "      'initialize_bias': CustomBiasInitializer\n",
    "    }\n",
    "    print(\"loading saved model architecture and weights/biases\")\n",
    "    model = load_model(model_path, custom_objects=custom_objects)\n",
    "  else:\n",
    "    model = get_siamese_model(input_shape)\n",
    "    if not refresh and os.path.exists(model_weights_path) and os.path.isfile(model_weights_path):\n",
    "      print(\"loading saved model weights\")\n",
    "      model.load_weights(model_weights_path)\n",
    "    \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hFIP-javMPFG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training process!\n",
      "-------------------------------------\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4001 is out of bounds for axis 0 with size 1001",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-0e142c1772c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-35758b7454f5>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, batch_size, epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mt_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time for training: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-2781d17eb7b4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, epochs, batch_size)\u001b[0m\n\u001b[1;32m     42\u001b[0m                                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                                       \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                                       callbacks=callbacks)\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m(uid)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \"\"\"\n\u001b[0;32m--> 626\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-2781d17eb7b4>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(self, batch_size, s)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m               \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4001 is out of bounds for axis 0 with size 1001"
     ]
    }
   ],
   "source": [
    "model = load_saved_model(refresh=True)\n",
    "history, model = train_and_evaluate(model, batch_size=64, epochs=500)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "iEoSBRhyyvvd",
    "outputId": "e452d114-c32b-4706-d270-3ce0ba99aec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 8392 is out of bounds for axis 0 with size 1001",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-0b33340eeb57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-2ac310c71600>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, batch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-2781d17eb7b4>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model, batch_size)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m(uid)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \"\"\"\n\u001b[0;32m--> 626\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-2781d17eb7b4>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(self, batch_size, s)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m               \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 8392 is out of bounds for axis 0 with size 1001"
     ]
    }
   ],
   "source": [
    "model = load_saved_model()\n",
    "evaluate(model, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Kl11xO1E2osu",
    "pZCTEz312vsW",
    "7jC2q5xz26Rc",
    "jtnrdnLL29QX",
    "nPboHuEUCBTn",
    "Q5h7QU2IKSH9",
    "xz6hlQOOC_0b"
   ],
   "name": "Dupe Detection by Siamese Network(Final).ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
